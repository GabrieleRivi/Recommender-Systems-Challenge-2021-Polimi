{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad8a2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/gabriele/PycharmProjects/RecSys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feea8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.utils import create_URM, create_ICM, combine_matrices, write_submission, create_submission\n",
    "from src.Evaluation.Evaluator import EvaluatorHoldout\n",
    "from src.Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad3b3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "URM = create_URM()\n",
    "ICM = create_ICM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66e9d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 15 (0.11 %) of 13650 users have no sampled items\n",
      "Warning: 23 (0.17 %) of 13650 users have no sampled items\n",
      "EvaluatorHoldout: Ignoring 13635 ( 0.1%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 13627 ( 0.2%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "URM_train_validation,URM_test = split_train_in_two_percentage_global_sample(URM,train_percentage=0.85)\n",
    "URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train_validation,train_percentage=0.85)\n",
    "\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "759353b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.63, test 0.11.\n",
      "AUC: train 0.93, test 0.91.\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(URM_train, epochs=10)\n",
    "\n",
    "train_precision = precision_at_k(model, URM_train, k=10).mean()\n",
    "test_precision = precision_at_k(model, URM_test, k=10).mean()\n",
    "\n",
    "train_auc = auc_score(model, URM_train).mean()\n",
    "test_auc = auc_score(model, URM_test).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a12e2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In order to evaluate put it in a recommender class\n",
    "from src.Recommenders.Base.BaseRecommender import BaseRecommender\n",
    "from lightfm import LightFM\n",
    "import numpy as np\n",
    "\n",
    "class LightFMCFRecommender(BaseRecommender):\n",
    "    \"\"\"LightFMCFRecommender\"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"LightFMCFRecommender\"\n",
    "\n",
    "    def __init__(self, URM_train):\n",
    "        super(LightFMCFRecommender, self).__init__(URM_train)\n",
    "\n",
    "\n",
    "    def fit(self, epochs = 300, alpha = 1e-6, n_factors = 30, n_threads = 4):\n",
    "        \n",
    "        # Let's fit a WARP model\n",
    "        self.lightFM_model = LightFM(loss='warp',\n",
    "                                     item_alpha=alpha,\n",
    "                                     no_components=n_factors)\n",
    "\n",
    "        self.lightFM_model = self.lightFM_model.fit(URM_train, \n",
    "                                       epochs=epochs,\n",
    "                                       num_threads=n_threads)\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute = None):\n",
    "        \n",
    "        # Create a single (n_items, ) array with the item score, then copy it for every user\n",
    "        items_to_compute = np.arange(self.n_items)\n",
    "        \n",
    "        item_scores = - np.ones((len(user_id_array), self.n_items)) * np.inf\n",
    "\n",
    "        for user_index, user_id in enumerate(user_id_array):\n",
    "            item_scores[user_index] = self.lightFM_model.predict(int(user_id), \n",
    "                                                                 items_to_compute)\n",
    "\n",
    "        return item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d8cf63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "SearchBayesianSkopt: Testing config: {'epochs': 36, 'alpha': 0.014320670446157282, 'n_threads': 10}\n",
      "LightFMCFRecommender: URM Detected 1 ( 0.0%) items with no interactions.\n",
      "EvaluatorHoldout: Processed 13627 (100.0%) in 21.25 sec. Users per second: 641\n",
      "SearchBayesianSkopt: New best config found. Config 0: {'epochs': 36, 'alpha': 0.014320670446157282, 'n_threads': 10} - results: PRECISION: 0.0002789, PRECISION_RECALL_MIN_DEN: 0.0002862, RECALL: 0.0000568, MAP: 0.0000693, MAP_MIN_DEN: 0.0000704, MRR: 0.0006931, NDCG: 0.0002609, F1: 0.0000943, HIT_RATE: 0.0027886, ARHR_ALL_HITS: 0.0006931, NOVELTY: 0.0097618, AVERAGE_POPULARITY: 0.0035180, DIVERSITY_MEAN_INTER_LIST: 0.6583253, DIVERSITY_HERFINDAHL: 0.9658277, COVERAGE_ITEM: 0.0048175, COVERAGE_ITEM_CORRECT: 0.0011629, COVERAGE_USER: 0.9983150, COVERAGE_USER_CORRECT: 0.0027839, DIVERSITY_GINI: 0.0015383, SHANNON_ENTROPY: 5.1394563, RATIO_DIVERSITY_HERFINDAHL: 0.9662001, RATIO_DIVERSITY_GINI: 0.0062050, RATIO_SHANNON_ENTROPY: 0.4147914, RATIO_AVERAGE_POPULARITY: 0.0171164, RATIO_NOVELTY: 0.0508546, \n",
      "\n",
      "EvaluatorHoldout: Processed 13635 (100.0%) in 20.55 sec. Users per second: 664\n",
      "SearchBayesianSkopt: Config evaluated with evaluator_test. Config: {'epochs': 36, 'alpha': 0.014320670446157282, 'n_threads': 10} - results:\n",
      "CUTOFF: 10 - PRECISION: 0.0004694, PRECISION_RECALL_MIN_DEN: 0.0004702, RECALL: 0.0000774, MAP: 0.0001237, MAP_MIN_DEN: 0.0001239, MRR: 0.0012369, NDCG: 0.0004429, F1: 0.0001328, HIT_RATE: 0.0046938, ARHR_ALL_HITS: 0.0012369, NOVELTY: 0.0097617, AVERAGE_POPULARITY: 0.0035192, DIVERSITY_MEAN_INTER_LIST: 0.6584295, DIVERSITY_HERFINDAHL: 0.9658381, COVERAGE_ITEM: 0.0048175, COVERAGE_ITEM_CORRECT: 0.0017166, COVERAGE_USER: 0.9989011, COVERAGE_USER_CORRECT: 0.0046886, DIVERSITY_GINI: 0.0015387, SHANNON_ENTROPY: 5.1397989, RATIO_DIVERSITY_HERFINDAHL: 0.9662105, RATIO_DIVERSITY_GINI: 0.0062066, RATIO_SHANNON_ENTROPY: 0.4148190, RATIO_AVERAGE_POPULARITY: 0.0171222, RATIO_NOVELTY: 0.0508543, \n",
      "\n",
      "\n",
      "SearchBayesianSkopt: Saving model in logs/LightFMCFRecommender\n",
      "\n",
      "SearchBayesianSkopt: Config 0 Exception. Config: {'epochs': 36, 'alpha': 0.014320670446157282, 'n_threads': 10} - Exception: Traceback (most recent call last):\n",
      "  File \"/Users/gabriele/PycharmProjects/RecSys/src/HyperparameterTuning/SearchAbstractClass.py\", line 530, in _objective_function\n",
      "    recommender_instance.save_model(self.output_folder_path, file_name =self.output_file_name_root + \"_best_model\")\n",
      "  File \"/Users/gabriele/PycharmProjects/RecSys/src/Recommenders/Base/BaseRecommender.py\", line 221, in save_model\n",
      "    raise NotImplementedError(\"BaseRecommender: save_model not implemented\")\n",
      "NotImplementedError: BaseRecommender: save_model not implemented\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriele/PycharmProjects/RecSys/src/HyperparameterTuning/SearchAbstractClass.py\", line 530, in _objective_function\n",
      "    recommender_instance.save_model(self.output_folder_path, file_name =self.output_file_name_root + \"_best_model\")\n",
      "  File \"/Users/gabriele/PycharmProjects/RecSys/src/Recommenders/Base/BaseRecommender.py\", line 221, in save_model\n",
      "    raise NotImplementedError(\"BaseRecommender: save_model not implemented\")\n",
      "NotImplementedError: BaseRecommender: save_model not implemented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 191.8968\n",
      "Function value obtained: 65504.0000\n",
      "Current minimum: 65504.0000\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "SearchBayesianSkopt: Testing config: {'epochs': 359, 'alpha': 0.05939570163937069, 'n_threads': 10}\n",
      "LightFMCFRecommender: URM Detected 1 ( 0.0%) items with no interactions.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6k/tknbbysd0fd7b8blw3n8zjjm0000gn/T/ipykernel_35294/1082484309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0moutput_folder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"logs/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m tuning_class.search(recommender_input_args=recommender_input_args,\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0mhyperparameter_search_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters_range_dictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mmetric_to_optimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MAP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/RecSys/src/HyperparameterTuning/SearchBayesianSkopt.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, recommender_input_args, hyperparameter_search_space, metric_to_optimize, cutoff_to_optimize, n_cases, n_random_starts, output_folder_path, output_file_name_root, save_model, save_metadata, resume_from_saved, recommender_input_args_last_test, evaluate_on_test, max_total_time)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0;31m# of \"Searching for the next optimal point\". This may be due to a bug in the print rather than the underlying process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;31m# https://github.com/scikit-optimize/scikit-optimize/issues/949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 self.result = gp_minimize(self._objective_function_list_input,\n\u001b[0m\u001b[1;32m    339\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparams_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                                           \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    257\u001b[0m             noise=noise)\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0macq_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/RecSys/src/HyperparameterTuning/SearchBayesianSkopt.py\u001b[0m in \u001b[0;36m_objective_function_list_input\u001b[0;34m(self, current_fit_hyperparameters_list_of_values)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mcurrent_fit_hyperparameters_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparams_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_fit_hyperparameters_list_of_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_fit_hyperparameters_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# The search can only progress if there is at least a valid config in the initial random start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/RecSys/src/HyperparameterTuning/SearchAbstractClass.py\u001b[0m in \u001b[0;36m_objective_function\u001b[0;34m(self, current_fit_hyperparameters_dict)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;31m# If getting a interrupt, terminate without saving the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/RecSys/src/HyperparameterTuning/SearchAbstractClass.py\u001b[0m in \u001b[0;36m_objective_function\u001b[0;34m(self, current_fit_hyperparameters_dict)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mwas_already_evaluated_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwas_already_evaluated_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_was_already_evaluated_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_fit_hyperparameters_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommender_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_on_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_fit_hyperparameters_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwas_already_evaluated_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwas_already_evaluated_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mresult_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cutoff_to_optimize\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/RecSys/src/HyperparameterTuning/SearchAbstractClass.py\u001b[0m in \u001b[0;36m_evaluate_on_validation\u001b[0;34m(self, current_fit_hyperparameters, was_already_evaluated_flag, was_already_evaluated_index)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hyperparameters_df\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_counter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_fit_hyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mrecommender_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_fit_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/RecSys/src/HyperparameterTuning/SearchAbstractClass.py\u001b[0m in \u001b[0;36m_fit_model\u001b[0;34m(self, current_fit_hyperparameters)\u001b[0m\n\u001b[1;32m    302\u001b[0m                                                       **self.recommender_input_args.CONSTRUCTOR_KEYWORD_ARGS)\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         recommender_instance.fit(*self.recommender_input_args.FIT_POSITIONAL_ARGS,\n\u001b[0m\u001b[1;32m    305\u001b[0m                                  \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommender_input_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIT_KEYWORD_ARGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                                  **current_fit_hyperparameters)\n",
      "\u001b[0;32m/var/folders/6k/tknbbysd0fd7b8blw3n8zjjm0000gn/T/ipykernel_35294/3983080861.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, alpha, n_factors, n_threads)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                      no_components=n_factors)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         self.lightFM_model = self.lightFM_model.fit(URM_train, \n\u001b[0m\u001b[1;32m     23\u001b[0m                                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                        num_threads=n_threads)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         return self.fit_partial(\n\u001b[0m\u001b[1;32m    534\u001b[0m             \u001b[0minteractions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0muser_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mfit_partial\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             self._run_epoch(\n\u001b[0m\u001b[1;32m    639\u001b[0m                 \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/jupyter/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, item_features, user_features, interactions, sample_weight, num_threads, loss)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;31m# Call the estimation routines.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"warp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             fit_warp(\n\u001b[0m\u001b[1;32m    680\u001b[0m                 \u001b[0mCSRMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0mCSRMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.HyperparameterTuning.SearchBayesianSkopt import SearchBayesianSkopt\n",
    "from src.HyperparameterTuning.SearchAbstractClass import SearchInputRecommenderArgs\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "hyperparameters_range_dictionary = {\n",
    "    \"epochs\": Integer(10,500),\n",
    "    \"alpha\": Real(1e-6,0.1),\n",
    "    \"n_threads\": Categorical([10])\n",
    "}\n",
    "recommender_input_args = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [URM_train],     # For a CBF model simply put [URM_train, ICM_train]\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = {}\n",
    ")\n",
    "recommender_input_args_last_test = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [URM_train_validation],     # For a CBF model simply put [URM_train_validation, ICM_train]\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = {}\n",
    ")\n",
    "\n",
    "tuning_class = SearchBayesianSkopt(recommender_class=LightFMCFRecommender,\n",
    "                                   evaluator_validation=evaluator_validation,\n",
    "                                   evaluator_test=evaluator_test)\n",
    "\n",
    "n_cases = 50\n",
    "n_random_starts = n_cases*0.3\n",
    "output_folder_path = \"logs/\"\n",
    "\n",
    "tuning_class.search(recommender_input_args=recommender_input_args,\n",
    "                    hyperparameter_search_space=hyperparameters_range_dictionary,\n",
    "                    metric_to_optimize=\"MAP\",\n",
    "                    cutoff_to_optimize= 10,\n",
    "                    n_cases= n_cases,\n",
    "                    n_random_starts=n_random_starts,\n",
    "                    output_folder_path=output_folder_path,\n",
    "                    output_file_name_root=LightFMCFRecommender.RECOMMENDER_NAME,\n",
    "                    save_model=\"best\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38606c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
